#!/usr/bin/env python3
"""
è®­ç»ƒæ•°æ®å‡†å¤‡è„šæœ¬
ç”¨äºç”ŸæˆCRNNå’ŒCRAFTæ¨¡å‹çš„è®­ç»ƒæ•°æ®
"""

import os
import cv2
import numpy as np
import json
from typing import List, Tuple, Dict
import argparse
from pathlib import Path


class TrainingDataPreparer:
    """è®­ç»ƒæ•°æ®å‡†å¤‡å™¨"""
    
    def __init__(self):
        self.crnn_height = 32  # CRNNæ¨¡å‹å›ºå®šé«˜åº¦
        
    def prepare_crnn_data(self, input_dir: str, output_dir: str):
        """
        å‡†å¤‡CRNNè®­ç»ƒæ•°æ®
        
        Args:
            input_dir: åŒ…å«èº«ä»½è¯å›¾åƒçš„ç›®å½•
            output_dir: è¾“å‡ºè®­ç»ƒæ•°æ®çš„ç›®å½•
        """
        print("ğŸ”§ å‡†å¤‡CRNNè®­ç»ƒæ•°æ®...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        images_dir = Path(output_dir) / "images"
        images_dir.mkdir(parents=True, exist_ok=True)
        
        labels_file = Path(output_dir) / "labels.txt"
        
        # èº«ä»½è¯å¸¸è§æ–‡æœ¬æ ·æœ¬
        sample_texts = [
            "ä»»äºšå¤", "å¼ ä¸‰", "æå››", "ç‹äº”", "èµµå…­", "é’±ä¸ƒ", "å­™å…«", "å‘¨ä¹", "å´å",
            "ç”·", "å¥³",
            "æ±‰æ—", "æ»¡æ—", "è’™å¤æ—", "å›æ—", "è—æ—", "ç»´å¾å°”æ—", "è‹—æ—", "å½æ—",
            "1988å¹´12æœˆ4æ—¥", "1990å¹´1æœˆ1æ—¥", "1985å¹´3æœˆ15æ—¥", "1992å¹´8æœˆ20æ—¥",
            "æ²³å—çœå•†ä¸˜å¸‚ç¢é˜³åŒº", "åŒ—äº¬å¸‚æœé˜³åŒº", "ä¸Šæµ·å¸‚æµ¦ä¸œæ–°åŒº", "å¹¿ä¸œçœæ·±åœ³å¸‚",
            "411403198812047555", "110101199001010000", "320101198501010000",
            "å•†ä¸˜å¸‚å…¬å®‰å±€ç¢é˜³åˆ†å±€", "åŒ—äº¬å¸‚å…¬å®‰å±€æœé˜³åˆ†å±€", "ä¸Šæµ·å¸‚å…¬å®‰å±€æµ¦ä¸œåˆ†å±€",
            "2016.01.28-2036.01.28", "2010.01.01-2030.01.01", "2015.06.10-2035.06.10"
        ]
        
        with open(labels_file, 'w', encoding='utf-8') as f:
            for idx, text in enumerate(sample_texts):
                # ç”Ÿæˆæ–‡æœ¬å›¾åƒ
                image = self._generate_text_image(text)
                if image is not None:
                    image_name = f"{idx:05d}.jpg"
                    image_path = images_dir / image_name
                    cv2.imwrite(str(image_path), image)
                    f.write(f"{image_name} {text}\n")
                    print(f"  ç”Ÿæˆ: {image_name} -> {text}")
        
        print(f"âœ… CRNNè®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {output_dir}")
        print(f"   - å›¾åƒæ•°é‡: {len(sample_texts)}")
        print(f"   - æ ‡ç­¾æ–‡ä»¶: {labels_file}")
    
    def _generate_text_image(self, text: str) -> np.ndarray:
        """
        ç”Ÿæˆæ–‡æœ¬å›¾åƒ
        
        Args:
            text: è¦ç”Ÿæˆçš„æ–‡æœ¬
            
        Returns:
            ç”Ÿæˆçš„å›¾åƒæ•°ç»„
        """
        # å­—ä½“é…ç½®
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.8
        thickness = 2
        
        # è·å–æ–‡æœ¬å°ºå¯¸
        (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
        
        # è®¡ç®—å›¾åƒå°ºå¯¸
        padding = 10
        img_width = text_width + 2 * padding
        img_height = self.crnn_height
        
        # åˆ›å»ºç™½è‰²èƒŒæ™¯å›¾åƒ
        image = np.ones((img_height, img_width, 3), dtype=np.uint8) * 255
        
        # è®¡ç®—æ–‡æœ¬ä½ç½®ï¼ˆå±…ä¸­ï¼‰
        x = (img_width - text_width) // 2
        y = (img_height + text_height) // 2
        
        # ç»˜åˆ¶æ–‡æœ¬
        cv2.putText(image, text, (x, y), font, font_scale, (0, 0, 0), thickness)
        
        return image
    
    def prepare_craft_data(self, input_dir: str, output_dir: str):
        """
        å‡†å¤‡CRAFTè®­ç»ƒæ•°æ®
        
        Args:
            input_dir: åŒ…å«èº«ä»½è¯å›¾åƒçš„ç›®å½•
            output_dir: è¾“å‡ºè®­ç»ƒæ•°æ®çš„ç›®å½•
        """
        print("ğŸ”§ å‡†å¤‡CRAFTè®­ç»ƒæ•°æ®...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # å¤„ç†è¾“å…¥å›¾åƒ
        input_path = Path(input_dir)
        image_files = list(input_path.glob("*.jpg")) + list(input_path.glob("*.jpeg")) + list(input_path.glob("*.png"))
        
        for idx, image_file in enumerate(image_files):
            print(f"  å¤„ç†å›¾åƒ: {image_file.name}")
            
            # è¯»å–å›¾åƒ
            image = cv2.imread(str(image_file))
            if image is None:
                continue
            
            # å¤åˆ¶å›¾åƒåˆ°è¾“å‡ºç›®å½•
            output_image_name = f"img_{idx:03d}.jpg"
            output_image_path = output_path / output_image_name
            cv2.imwrite(str(output_image_path), image)
            
            # ç”Ÿæˆå¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶
            gt_file_name = f"gt_img_{idx:03d}.txt"
            gt_file_path = output_path / gt_file_name
            
            # æ¨¡æ‹Ÿæ ‡æ³¨æ•°æ®ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦äººå·¥æ ‡æ³¨ï¼‰
            sample_annotations = self._generate_sample_annotations(image.shape)
            
            with open(gt_file_path, 'w', encoding='utf-8') as f:
                for ann in sample_annotations:
                    f.write(f"{ann}\n")
            
            print(f"    ç”Ÿæˆæ ‡æ³¨: {gt_file_name}")
        
        print(f"âœ… CRAFTè®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {output_dir}")
        print(f"   - å›¾åƒæ•°é‡: {len(image_files)}")
    
    def _generate_sample_annotations(self, image_shape: Tuple[int, int, int]) -> List[str]:
        """
        ç”Ÿæˆç¤ºä¾‹æ ‡æ³¨æ•°æ®ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦äººå·¥æ ‡æ³¨ï¼‰
        
        Args:
            image_shape: å›¾åƒå°ºå¯¸
            
        Returns:
            æ ‡æ³¨æ•°æ®åˆ—è¡¨
        """
        h, w, _ = image_shape
        
        # æ¨¡æ‹Ÿèº«ä»½è¯ä¸Šçš„æ–‡æœ¬åŒºåŸŸ
        annotations = [
            f"100,50,200,50,200,80,100,80,å§“å",
            f"100,90,150,90,150,120,100,120,æ€§åˆ«", 
            f"100,130,180,130,180,160,100,160,æ°‘æ—",
            f"100,170,250,170,250,200,100,200,å‡ºç”Ÿæ—¥æœŸ",
            f"100,210,400,210,400,280,100,280,ä½å€",
            f"100,290,350,290,350,320,100,320,èº«ä»½è¯å·ç "
        ]
        
        # è°ƒæ•´åæ ‡åˆ°å›¾åƒèŒƒå›´å†…
        adjusted_annotations = []
        for ann in annotations:
            parts = ann.split(',')
            coords = [int(x) for x in parts[:8]]
            text = parts[8]
            
            # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
            for i in range(0, 8, 2):
                coords[i] = min(coords[i], w - 1)  # xåæ ‡
            for i in range(1, 8, 2):
                coords[i] = min(coords[i], h - 1)  # yåæ ‡
            
            adjusted_ann = ','.join([str(c) for c in coords] + [text])
            adjusted_annotations.append(adjusted_ann)
        
        return adjusted_annotations
    
    def create_dataset_info(self, output_dir: str):
        """
        åˆ›å»ºæ•°æ®é›†ä¿¡æ¯æ–‡ä»¶
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        dataset_info = {
            "name": "èº«ä»½è¯OCRè®­ç»ƒæ•°æ®é›†",
            "description": "ç”¨äºè®­ç»ƒèº«ä»½è¯è¯†åˆ«æ¨¡å‹çš„æ•°æ®é›†",
            "version": "1.0",
            "models": {
                "CRNN": {
                    "task": "æ–‡æœ¬è¯†åˆ«",
                    "input": "æ–‡æœ¬åŒºåŸŸå›¾åƒ",
                    "output": "è¯†åˆ«çš„æ–‡å­—",
                    "image_height": 32,
                    "data_format": "images/ + labels.txt"
                },
                "CRAFT": {
                    "task": "æ–‡æœ¬æ£€æµ‹", 
                    "input": "å®Œæ•´åœºæ™¯å›¾åƒ",
                    "output": "æ–‡æœ¬æ¡†åæ ‡",
                    "data_format": "images/ + gt_*.txt"
                }
            },
            "charset": "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZä¸­åäººæ°‘å…±å’Œå›½èº«ä»½è¯å§“åæ€§åˆ«æ°‘æ—å‡ºç”Ÿå¹´æœˆæ—¥ä½å€å…¬æ°‘å·ç ç­¾å‘æœºå…³æœ‰æ•ˆæœŸé™é•¿è‡³æ±‰æ—ç”·å¥³çœå¸‚å¿åŒºè¡—é“è·¯å·æ¥¼å®¤æ´¾å‡ºæ‰€å…¬å®‰å±€å…",
            "fields": [
                "å§“å", "æ€§åˆ«", "æ°‘æ—", "å‡ºç”Ÿ", "ä½å€", "å…¬æ°‘èº«ä»½å·ç ", "ç­¾å‘æœºå…³", "æœ‰æ•ˆæœŸé™"
            ]
        }
        
        info_file = Path(output_dir) / "dataset_info.json"
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(dataset_info, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“‹ æ•°æ®é›†ä¿¡æ¯å·²ä¿å­˜åˆ°: {info_file}")


def main():
    parser = argparse.ArgumentParser(description='è®­ç»ƒæ•°æ®å‡†å¤‡å·¥å…·')
    parser.add_argument('--input', type=str, help='è¾“å…¥å›¾åƒç›®å½•')
    parser.add_argument('--output', type=str, default='training_data', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--model', type=str, choices=['crnn', 'craft', 'both'], 
                       default='both', help='å‡†å¤‡å“ªä¸ªæ¨¡å‹çš„æ•°æ®')
    
    args = parser.parse_args()
    
    preparer = TrainingDataPreparer()
    
    if args.model in ['crnn', 'both']:
        # å‡†å¤‡CRNNæ•°æ®
        crnn_output = Path(args.output) / "crnn_data"
        preparer.prepare_crnn_data(args.input or ".", str(crnn_output))
    
    if args.model in ['craft', 'both']:
        # å‡†å¤‡CRAFTæ•°æ®
        craft_output = Path(args.output) / "craft_data"
        preparer.prepare_craft_data(args.input or ".", str(craft_output))
    
    # åˆ›å»ºæ•°æ®é›†ä¿¡æ¯
    preparer.create_dataset_info(args.output)
    
    print("\nğŸ‰ è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output}")
    print("\nğŸ“– ä½¿ç”¨è¯´æ˜:")
    print("1. CRNNè®­ç»ƒæ•°æ®ä½äº: crnn_data/")
    print("   - images/: æ–‡æœ¬å›¾åƒæ–‡ä»¶")
    print("   - labels.txt: å¯¹åº”çš„æ–‡æœ¬æ ‡ç­¾")
    print("2. CRAFTè®­ç»ƒæ•°æ®ä½äº: craft_data/")
    print("   - img_*.jpg: åœºæ™¯å›¾åƒ")
    print("   - gt_*.txt: å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶")
    print("3. æ•°æ®é›†ä¿¡æ¯: dataset_info.json")


if __name__ == "__main__":
    main() 