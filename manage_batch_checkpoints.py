"""
æ‰¹æ¬¡æ£€æŸ¥ç‚¹ç®¡ç†å·¥å…·
ç”¨äºæŸ¥çœ‹ã€åŠ è½½å’Œæ¸…ç†æŒ‰batchä¿å­˜çš„æ¨¡å‹æ£€æŸ¥ç‚¹
"""

import os
import torch
import argparse
from datetime import datetime
import glob
from models.text_detection import CRAFT


def list_checkpoints(save_dir):
    """åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹æ–‡ä»¶"""
    print(f"ğŸ” æ‰«æç›®å½•: {save_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰æ£€æŸ¥ç‚¹æ–‡ä»¶
    batch_checkpoints = glob.glob(os.path.join(save_dir, "checkpoint_epoch_*_batch_*.pth"))
    epoch_checkpoints = glob.glob(os.path.join(save_dir, "best_model.pth"))
    
    print(f"\nğŸ“‹ æ£€æŸ¥ç‚¹æ–‡ä»¶åˆ—è¡¨:")
    
    if epoch_checkpoints:
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹:")
        for cp in epoch_checkpoints:
            file_size = os.path.getsize(cp) / (1024 * 1024)  # MB
            mod_time = datetime.fromtimestamp(os.path.getmtime(cp))
            print(f"  {os.path.basename(cp)} - {file_size:.1f}MB - {mod_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    if batch_checkpoints:
        print(f"\nğŸ”„ æ‰¹æ¬¡æ£€æŸ¥ç‚¹ ({len(batch_checkpoints)}ä¸ª):")
        
        # æŒ‰æ—¶é—´æ’åº
        batch_checkpoints.sort(key=os.path.getmtime, reverse=True)
        
        total_size = 0
        for cp in batch_checkpoints[:10]:  # åªæ˜¾ç¤ºæœ€æ–°çš„10ä¸ª
            file_size = os.path.getsize(cp) / (1024 * 1024)  # MB
            total_size += file_size
            mod_time = datetime.fromtimestamp(os.path.getmtime(cp))
            print(f"  {os.path.basename(cp)} - {file_size:.1f}MB - {mod_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        if len(batch_checkpoints) > 10:
            print(f"  ... è¿˜æœ‰{len(batch_checkpoints) - 10}ä¸ªæ–‡ä»¶")
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ‰¹æ¬¡æ£€æŸ¥ç‚¹æ€»æ•°: {len(batch_checkpoints)}")
        print(f"  æ€»å¤§å°: {sum(os.path.getsize(cp) for cp in batch_checkpoints) / (1024 * 1024):.1f}MB")
    
    return batch_checkpoints, epoch_checkpoints


def load_checkpoint_info(checkpoint_path):
    """åŠ è½½å¹¶æ˜¾ç¤ºæ£€æŸ¥ç‚¹ä¿¡æ¯"""
    print(f"\nğŸ” æ£€æŸ¥ç‚¹è¯¦æƒ…: {os.path.basename(checkpoint_path)}")
    
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        print(f"  Epoch: {checkpoint.get('epoch', 'N/A')}")
        print(f"  Batch: {checkpoint.get('batch', 'N/A')}")
        print(f"  æ€»æ‰¹æ¬¡æ•°: {checkpoint.get('total_batches', 'N/A')}")
        print(f"  è®­ç»ƒæŸå¤±: {checkpoint.get('train_loss', 'N/A'):.4f}")
        print(f"  å­—ç¬¦æŸå¤±: {checkpoint.get('cls_loss', 'N/A'):.4f}")
        print(f"  é“¾æ¥æŸå¤±: {checkpoint.get('geo_loss', 'N/A'):.4f}")
        
        if 'val_loss' in checkpoint:
            print(f"  éªŒè¯æŸå¤±: {checkpoint['val_loss']:.4f}")
        
        # æ£€æŸ¥æ¨¡å‹æƒé‡
        state_dict = checkpoint.get('model_state_dict', {})
        print(f"  æ¨¡å‹å‚æ•°æ•°é‡: {len(state_dict)}")
        
        return checkpoint
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        return None


def load_model_from_checkpoint(checkpoint_path, device='cpu'):
    """ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹"""
    print(f"ğŸ¤– ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹: {os.path.basename(checkpoint_path)}")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        model = CRAFT(pretrained=False, freeze=False).to(device)
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        print(f"  - æ¥è‡ªEpoch {checkpoint.get('epoch', 'N/A')}, Batch {checkpoint.get('batch', 'N/A')}")
        print(f"  - è®­ç»ƒæŸå¤±: {checkpoint.get('train_loss', 'N/A'):.4f}")
        
        return model, checkpoint
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None, None


def clean_old_checkpoints(save_dir, keep_count=10):
    """æ¸…ç†æ—§çš„æ‰¹æ¬¡æ£€æŸ¥ç‚¹ï¼Œåªä¿ç•™æœ€æ–°çš„å‡ ä¸ª"""
    print(f"ğŸ§¹ æ¸…ç†æ—§æ£€æŸ¥ç‚¹ï¼Œä¿ç•™æœ€æ–°{keep_count}ä¸ª...")
    
    batch_checkpoints = glob.glob(os.path.join(save_dir, "checkpoint_epoch_*_batch_*.pth"))
    
    if len(batch_checkpoints) <= keep_count:
        print(f"  å½“å‰åªæœ‰{len(batch_checkpoints)}ä¸ªæ£€æŸ¥ç‚¹ï¼Œæ— éœ€æ¸…ç†")
        return
    
    # æŒ‰æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„
    batch_checkpoints.sort(key=os.path.getmtime, reverse=True)
    to_delete = batch_checkpoints[keep_count:]
    
    total_size_deleted = 0
    for cp in to_delete:
        try:
            size = os.path.getsize(cp)
            os.remove(cp)
            total_size_deleted += size
            print(f"  âœ… åˆ é™¤: {os.path.basename(cp)}")
        except Exception as e:
            print(f"  âŒ åˆ é™¤å¤±è´¥: {os.path.basename(cp)} - {e}")
    
    print(f"ğŸ‰ æ¸…ç†å®Œæˆï¼åˆ é™¤{len(to_delete)}ä¸ªæ–‡ä»¶ï¼Œé‡Šæ”¾{total_size_deleted / (1024 * 1024):.1f}MBç©ºé—´")


def main():
    parser = argparse.ArgumentParser(description='æ‰¹æ¬¡æ£€æŸ¥ç‚¹ç®¡ç†å·¥å…·')
    parser.add_argument('--save_dir', type=str, default='checkpoints_improved', help='æ£€æŸ¥ç‚¹ç›®å½•')
    parser.add_argument('--action', choices=['list', 'info', 'load', 'clean'], default='list', help='æ“ä½œç±»å‹')
    parser.add_argument('--checkpoint', type=str, help='ç‰¹å®šæ£€æŸ¥ç‚¹æ–‡ä»¶å')
    parser.add_argument('--keep_count', type=int, default=10, help='æ¸…ç†æ—¶ä¿ç•™çš„æ£€æŸ¥ç‚¹æ•°é‡')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.save_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.save_dir}")
        return
    
    if args.action == 'list':
        list_checkpoints(args.save_dir)
        
    elif args.action == 'info':
        if not args.checkpoint:
            print("âŒ è¯·ä½¿ç”¨ --checkpoint æŒ‡å®šæ£€æŸ¥ç‚¹æ–‡ä»¶")
            return
        
        checkpoint_path = os.path.join(args.save_dir, args.checkpoint)
        if not os.path.exists(checkpoint_path):
            print(f"âŒ æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
            return
        
        load_checkpoint_info(checkpoint_path)
        
    elif args.action == 'load':
        if not args.checkpoint:
            print("âŒ è¯·ä½¿ç”¨ --checkpoint æŒ‡å®šæ£€æŸ¥ç‚¹æ–‡ä»¶")
            return
        
        checkpoint_path = os.path.join(args.save_dir, args.checkpoint)
        if not os.path.exists(checkpoint_path):
            print(f"âŒ æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
            return
        
        model, checkpoint = load_model_from_checkpoint(checkpoint_path)
        if model:
            print(f"ğŸ’¡ æ¨¡å‹å·²åŠ è½½ï¼Œå¯ä»¥ç”¨äºæ¨ç†æˆ–ç»§ç»­è®­ç»ƒ")
        
    elif args.action == 'clean':
        clean_old_checkpoints(args.save_dir, args.keep_count)
    
    print()


if __name__ == "__main__":
    main() 