"""
CRAFTæ¨¡å‹è®­ç»ƒè„šæœ¬
ç”¨äºè®­ç»ƒèº«ä»½è¯æ–‡æœ¬æ£€æµ‹æ¨¡å‹
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import cv2
import numpy as np
from PIL import Image
import json
import argparse
from tqdm import tqdm
import logging
from pathlib import Path
import math

from models.text_detection import CRAFT
from utils.image_processing import IDCardPreprocessor


class CRAFTDataset(Dataset):
    """CRAFTæ–‡æœ¬æ£€æµ‹æ•°æ®é›†"""
    
    def __init__(self, data_dir, transform=None):
        self.data_dir = Path(data_dir)
        self.transform = transform
        
        # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒå’Œå¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶
        self.samples = []
        for img_file in self.data_dir.glob("img_*.jpg"):
            gt_file = self.data_dir / f"gt_{img_file.stem}.txt"
            if gt_file.exists():
                self.samples.append({
                    'image': img_file,
                    'gt': gt_file
                })
        
        print(f"åŠ è½½ {len(self.samples)} ä¸ªè®­ç»ƒæ ·æœ¬")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        image = cv2.imread(str(sample['image']))
        if image is None:
            raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {sample['image']}")
        
        # åŠ è½½æ ‡æ³¨
        text_boxes = self._load_annotations(sample['gt'])
        
        # ç”Ÿæˆè®­ç»ƒç›®æ ‡
        char_heatmap, link_heatmap = self._generate_heatmaps(image, text_boxes)
        
        # å›¾åƒé¢„å¤„ç†
        if self.transform:
            image = self.transform(image)
        
        # è°ƒæ•´å›¾åƒå°ºå¯¸
        image, char_heatmap, link_heatmap = self._resize_data(
            image, char_heatmap, link_heatmap
        )
        
        # è½¬æ¢ä¸ºtensor
        image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0
        char_heatmap = torch.from_numpy(char_heatmap).float()
        link_heatmap = torch.from_numpy(link_heatmap).float()
        
        return image, char_heatmap, link_heatmap
    
    def _load_annotations(self, gt_file):
        """åŠ è½½æ ‡æ³¨æ–‡ä»¶"""
        text_boxes = []
        
        with open(gt_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    parts = line.split(',')
                    if len(parts) >= 8:
                        # æå–åæ ‡ç‚¹
                        coords = []
                        for i in range(0, 8, 2):
                            x = int(parts[i])
                            y = int(parts[i + 1])
                            coords.append([x, y])
                        
                        # æå–æ–‡æœ¬ï¼ˆå¦‚æœæœ‰ï¼‰
                        text = parts[8] if len(parts) > 8 else ""
                        
                        text_boxes.append({
                            'coords': np.array(coords),
                            'text': text
                        })
        
        return text_boxes
    
    def _generate_heatmaps(self, image, text_boxes):
        """ç”Ÿæˆå­—ç¬¦çº§å’Œé“¾æ¥çº§çƒ­å›¾"""
        h, w = image.shape[:2]
        
        # åˆå§‹åŒ–çƒ­å›¾
        char_heatmap = np.zeros((h, w), dtype=np.float32)
        link_heatmap = np.zeros((h, w), dtype=np.float32)
        
        for box in text_boxes:
            coords = box['coords']
            
            # ç”Ÿæˆå­—ç¬¦çº§çƒ­å›¾
            self._generate_char_heatmap(char_heatmap, coords)
            
            # ç”Ÿæˆé“¾æ¥çº§çƒ­å›¾
            self._generate_link_heatmap(link_heatmap, coords)
        
        return char_heatmap, link_heatmap
    
    def _generate_char_heatmap(self, heatmap, coords):
        """ç”Ÿæˆå­—ç¬¦çº§çƒ­å›¾"""
        # ä½¿ç”¨é«˜æ–¯æ ¸ç”Ÿæˆçƒ­å›¾
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…CRAFTä½¿ç”¨æ›´å¤æ‚çš„æ–¹æ³•
        
        # è®¡ç®—æ–‡æœ¬æ¡†çš„ä¸­å¿ƒå’Œæ–¹å‘
        center_x = np.mean(coords[:, 0])
        center_y = np.mean(coords[:, 1])
        
        # è®¡ç®—æ–‡æœ¬æ¡†çš„å®½åº¦å’Œé«˜åº¦
        width = np.linalg.norm(coords[1] - coords[0])
        height = np.linalg.norm(coords[3] - coords[0])
        
        # ç”Ÿæˆé«˜æ–¯çƒ­å›¾
        sigma = min(width, height) / 6
        self._add_gaussian_heatmap(heatmap, center_x, center_y, sigma)
    
    def _generate_link_heatmap(self, heatmap, coords):
        """ç”Ÿæˆé“¾æ¥çº§çƒ­å›¾"""
        # åœ¨å­—ç¬¦ä¹‹é—´ç”Ÿæˆè¿æ¥
        # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„æ–¹æ³•
        
        # è®¡ç®—æ–‡æœ¬æ¡†çš„å››ä¸ªè¾¹çš„ä¸­ç‚¹
        for i in range(len(coords)):
            j = (i + 1) % len(coords)
            
            start_x, start_y = coords[i]
            end_x, end_y = coords[j]
            
            # åœ¨è¾¹ä¸Šç”Ÿæˆè¿æ¥
            mid_x = (start_x + end_x) / 2
            mid_y = (start_y + end_y) / 2
            
            sigma = min(abs(end_x - start_x), abs(end_y - start_y)) / 4
            if sigma > 0:
                self._add_gaussian_heatmap(heatmap, mid_x, mid_y, sigma)
    
    def _add_gaussian_heatmap(self, heatmap, center_x, center_y, sigma):
        """æ·»åŠ é«˜æ–¯çƒ­å›¾"""
        h, w = heatmap.shape
        
        # è®¡ç®—é«˜æ–¯æ ¸çš„èŒƒå›´
        radius = int(sigma * 3)
        
        for y in range(max(0, int(center_y - radius)), 
                      min(h, int(center_y + radius + 1))):
            for x in range(max(0, int(center_x - radius)), 
                          min(w, int(center_x + radius + 1))):
                
                # è®¡ç®—é«˜æ–¯å€¼
                dist_sq = (x - center_x)**2 + (y - center_y)**2
                value = math.exp(-dist_sq / (2 * sigma**2))
                
                # å–æœ€å¤§å€¼
                heatmap[y, x] = max(heatmap[y, x], value)
    
    def _resize_data(self, image, char_heatmap, link_heatmap, input_size=512, target_size=256):
        """
        è°ƒæ•´æ•°æ®å°ºå¯¸
        input_size: è¾“å…¥å›¾åƒå°ºå¯¸ (ç”¨äºVGG16ç‰¹å¾æå–)
        target_size: ç›®æ ‡çƒ­å›¾å°ºå¯¸ (åŒ¹é…CRAFTè¾“å‡º)
        """
        h, w = image.shape[:2]
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale = input_size / max(h, w)
        new_h, new_w = int(h * scale), int(w * scale)
        
        # è°ƒæ•´å›¾åƒå°ºå¯¸åˆ°input_size
        image = cv2.resize(image, (new_w, new_h))
        
        # å¡«å……å›¾åƒåˆ°input_size
        pad_h = input_size - new_h
        pad_w = input_size - new_w
        
        image = cv2.copyMakeBorder(
            image, 0, pad_h, 0, pad_w, cv2.BORDER_CONSTANT, value=0
        )
        
        # è°ƒæ•´çƒ­å›¾å°ºå¯¸åˆ°target_size (åŒ¹é…CRAFTè¾“å‡º)
        target_scale = target_size / max(h, w)
        target_new_h, target_new_w = int(h * target_scale), int(w * target_scale)
        
        char_heatmap = cv2.resize(char_heatmap, (target_new_w, target_new_h))
        link_heatmap = cv2.resize(link_heatmap, (target_new_w, target_new_h))
        
        # å¡«å……çƒ­å›¾åˆ°target_size
        target_pad_h = target_size - target_new_h
        target_pad_w = target_size - target_new_w
        
        char_heatmap = cv2.copyMakeBorder(
            char_heatmap, 0, target_pad_h, 0, target_pad_w, cv2.BORDER_CONSTANT, value=0
        )
        link_heatmap = cv2.copyMakeBorder(
            link_heatmap, 0, target_pad_h, 0, target_pad_w, cv2.BORDER_CONSTANT, value=0
        )
        
        return image, char_heatmap, link_heatmap


class CRAFTLoss(nn.Module):
    """CRAFTæŸå¤±å‡½æ•°"""
    
    def __init__(self):
        super(CRAFTLoss, self).__init__()
        self.mse_loss = nn.MSELoss()
    
    def forward(self, y_true_cls, y_pred_cls, y_true_geo, y_pred_geo):
        """
        è®¡ç®—CRAFTæŸå¤±
        
        Args:
            y_true_cls: çœŸå®å­—ç¬¦çƒ­å›¾
            y_pred_cls: é¢„æµ‹å­—ç¬¦çƒ­å›¾  
            y_true_geo: çœŸå®é“¾æ¥çƒ­å›¾
            y_pred_geo: é¢„æµ‹é“¾æ¥çƒ­å›¾
        """
        # å­—ç¬¦æ£€æµ‹æŸå¤±
        cls_loss = self.mse_loss(y_pred_cls, y_true_cls)
        
        # é“¾æ¥æ£€æµ‹æŸå¤±
        geo_loss = self.mse_loss(y_pred_geo, y_true_geo)
        
        # æ€»æŸå¤±
        total_loss = cls_loss + geo_loss
        
        return total_loss, cls_loss, geo_loss


class CRAFTTrainer:
    """CRAFTè®­ç»ƒå™¨"""
    
    def __init__(self, model, device):
        self.model = model
        self.device = device
        self.criterion = CRAFTLoss()
        
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def train_epoch(self, dataloader, optimizer, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        total_cls_loss = 0
        total_geo_loss = 0
        
        pbar = tqdm(dataloader, desc=f'Epoch {epoch}')
        
        for batch_idx, (images, char_heatmaps, link_heatmaps) in enumerate(pbar):
            images = images.to(self.device)
            char_heatmaps = char_heatmaps.to(self.device)
            link_heatmaps = link_heatmaps.to(self.device)
            
            optimizer.zero_grad()
            
            try:
                # å‰å‘ä¼ æ’­
                outputs, _ = self.model(images)
                
                # æå–é¢„æµ‹ç»“æœ (outputs shape: [batch, height, width, 2])
                pred_char = outputs[:, :, :, 0]  # å­—ç¬¦çƒ­å›¾ [batch, height, width]
                pred_link = outputs[:, :, :, 1]  # é“¾æ¥çƒ­å›¾ [batch, height, width]
                
                # è®¡ç®—æŸå¤± (targetå’Œpredictionéƒ½æ˜¯[batch, height, width])
                loss, cls_loss, geo_loss = self.criterion(
                    char_heatmaps, pred_char,
                    link_heatmaps, pred_link
                )
                
                # åå‘ä¼ æ’­
                loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 5.0)
                
                optimizer.step()
                
                total_loss += loss.item()
                total_cls_loss += cls_loss.item()
                total_geo_loss += geo_loss.item()
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({
                    'loss': loss.item(),
                    'cls': cls_loss.item(),
                    'geo': geo_loss.item()
                })
                
            except Exception as e:
                print(f"è®­ç»ƒæ‰¹æ¬¡å‡ºé”™: {e}")
                continue
        
        avg_loss = total_loss / len(dataloader) if len(dataloader) > 0 else 0
        avg_cls_loss = total_cls_loss / len(dataloader) if len(dataloader) > 0 else 0
        avg_geo_loss = total_geo_loss / len(dataloader) if len(dataloader) > 0 else 0
        
        self.logger.info(
            f'Epoch {epoch}, Loss: {avg_loss:.4f}, '
            f'Cls: {avg_cls_loss:.4f}, Geo: {avg_geo_loss:.4f}'
        )
        
        return avg_loss, avg_cls_loss, avg_geo_loss
    
    def validate(self, dataloader):
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        total_loss = 0
        total_cls_loss = 0
        total_geo_loss = 0
        
        with torch.no_grad():
            for images, char_heatmaps, link_heatmaps in dataloader:
                images = images.to(self.device)
                char_heatmaps = char_heatmaps.to(self.device)
                link_heatmaps = link_heatmaps.to(self.device)
                
                try:
                    # å‰å‘ä¼ æ’­
                    outputs, _ = self.model(images)
                    
                    # æå–é¢„æµ‹ç»“æœ (outputs shape: [batch, height, width, 2])
                    pred_char = outputs[:, :, :, 0]  # å­—ç¬¦çƒ­å›¾ [batch, height, width]
                    pred_link = outputs[:, :, :, 1]  # é“¾æ¥çƒ­å›¾ [batch, height, width]
                    
                    # è®¡ç®—æŸå¤± (targetå’Œpredictionéƒ½æ˜¯[batch, height, width])
                    loss, cls_loss, geo_loss = self.criterion(
                        char_heatmaps, pred_char,
                        link_heatmaps, pred_link
                    )
                    
                    total_loss += loss.item()
                    total_cls_loss += cls_loss.item()
                    total_geo_loss += geo_loss.item()
                    
                except Exception as e:
                    print(f"éªŒè¯æ‰¹æ¬¡å‡ºé”™: {e}")
                    continue
        
        avg_loss = total_loss / len(dataloader) if len(dataloader) > 0 else 0
        avg_cls_loss = total_cls_loss / len(dataloader) if len(dataloader) > 0 else 0
        avg_geo_loss = total_geo_loss / len(dataloader) if len(dataloader) > 0 else 0
        
        self.logger.info(
            f'Validation Loss: {avg_loss:.4f}, '
            f'Cls: {avg_cls_loss:.4f}, Geo: {avg_geo_loss:.4f}'
        )
        
        return avg_loss, avg_cls_loss, avg_geo_loss


def main():
    parser = argparse.ArgumentParser(description='è®­ç»ƒCRAFTæ¨¡å‹')
    parser.add_argument('--data_dir', type=str, help='è®­ç»ƒæ•°æ®ç›®å½•')
    parser.add_argument('--batch_size', type=int, default=8, help='æ‰¹å¤§å°')
    parser.add_argument('--epochs', type=int, default=100, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=0.001, help='å­¦ä¹ ç‡')
    parser.add_argument('--save_dir', type=str, default='checkpoints_craft', help='æ¨¡å‹ä¿å­˜ç›®å½•')
    parser.add_argument('--resume', type=str, help='æ¢å¤è®­ç»ƒçš„æ¨¡å‹è·¯å¾„')
    parser.add_argument('--pretrained', action='store_true', help='ä½¿ç”¨é¢„è®­ç»ƒæƒé‡')
    
    args = parser.parse_args()
    
    # é»˜è®¤ä½¿ç”¨ç”Ÿæˆçš„è®­ç»ƒæ•°æ®
    if not args.data_dir:
        args.data_dir = 'sample_training_data/craft_data'
    
    # æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.data_dir):
        print(f"é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {args.data_dir}")
        print("è¯·å…ˆè¿è¡Œ: python prepare_training_data.py --model craft")
        return
    
    # è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = CRAFTDataset(args.data_dir)
    
    if len(dataset) == 0:
        print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæ•°æ®")
        return
    
    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size]
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=0
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=0
    )
    
    print(f"è®­ç»ƒæ ·æœ¬: {len(train_dataset)}, éªŒè¯æ ·æœ¬: {len(val_dataset)}")
    
    # åˆ›å»ºæ¨¡å‹
    model = CRAFT(pretrained=args.pretrained, freeze=False).to(device)
    
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
    
    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(model.parameters(), lr=args.lr)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)
    
    # è®­ç»ƒå™¨
    trainer = CRAFTTrainer(model, device)
    
    # æ¢å¤è®­ç»ƒ
    start_epoch = 0
    if args.resume and os.path.exists(args.resume):
        checkpoint = torch.load(args.resume, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        print(f"ä»epoch {start_epoch}æ¢å¤è®­ç»ƒ")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_dir, exist_ok=True)
    
    # è®­ç»ƒå¾ªç¯
    best_loss = float('inf')
    
    for epoch in range(start_epoch, args.epochs):
        print(f"\n=== Epoch {epoch+1}/{args.epochs} ===")
        
        # è®­ç»ƒ
        train_loss, train_cls_loss, train_geo_loss = trainer.train_epoch(
            train_loader, optimizer, epoch
        )
        
        # éªŒè¯
        val_loss, val_cls_loss, val_geo_loss = trainer.validate(val_loader)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if val_loss < best_loss:
            best_loss = val_loss
            
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'train_loss': train_loss,
                'val_loss': val_loss,
                'train_cls_loss': train_cls_loss,
                'train_geo_loss': train_geo_loss,
                'val_cls_loss': val_cls_loss,
                'val_geo_loss': val_geo_loss
            }
            
            torch.save(checkpoint, os.path.join(args.save_dir, 'best_model.pth'))
            print(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒéªŒè¯æŸå¤±: {best_loss:.4f}")
        
        # å®šæœŸä¿å­˜
        if epoch % 10 == 0:
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'train_loss': train_loss,
                'val_loss': val_loss,
                'train_cls_loss': train_cls_loss,
                'train_geo_loss': train_geo_loss,
                'val_cls_loss': val_cls_loss,
                'val_geo_loss': val_geo_loss
            }
            
            torch.save(checkpoint, os.path.join(args.save_dir, f'checkpoint_epoch_{epoch}.pth'))
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: epoch_{epoch}.pth")
    
    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³æ¨¡å‹ä¿å­˜åœ¨: {args.save_dir}/best_model.pth")


if __name__ == "__main__":
    main() 