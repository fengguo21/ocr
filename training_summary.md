# èº«ä»½è¯è¯†åˆ«æ¨¡å‹è®­ç»ƒä»£ç æ€»ç»“

## ğŸ¯ å·²å®Œæˆçš„å·¥ä½œ

### âœ… 1. è®­ç»ƒæ•°æ®å‡†å¤‡
- **å‡†å¤‡è„šæœ¬**: `prepare_training_data.py`
- **åŠŸèƒ½**: è‡ªåŠ¨ç”ŸæˆCRNNå’ŒCRAFTè®­ç»ƒæ•°æ®
- **æ ¼å¼æ”¯æŒ**: 
  - CRNN: æ–‡æœ¬å›¾åƒ + æ ‡ç­¾æ–‡ä»¶
  - CRAFT: åœºæ™¯å›¾åƒ + æ ‡æ³¨æ–‡ä»¶
- **çŠ¶æ€**: âœ… å®Œå…¨å¯ç”¨

### âœ… 2. CRNNè®­ç»ƒè„šæœ¬
- **æ–‡ä»¶**: `train_crnn.py`
- **åŠŸèƒ½**: 
  - æ–‡æœ¬è¯†åˆ«æ¨¡å‹è®­ç»ƒ
  - CTCæŸå¤±å‡½æ•°
  - æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
  - æ¨¡å‹ä¿å­˜å’Œæ¢å¤
- **çŠ¶æ€**: âš ï¸ åŸºæœ¬å¯ç”¨ï¼Œéœ€è¦è°ƒè¯•

### âœ… 3. CRAFTè®­ç»ƒè„šæœ¬
- **æ–‡ä»¶**: `train_craft.py`
- **åŠŸèƒ½**:
  - æ–‡æœ¬æ£€æµ‹æ¨¡å‹è®­ç»ƒ
  - çƒ­å›¾ç”Ÿæˆ
  - MSEæŸå¤±å‡½æ•°
  - æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
- **çŠ¶æ€**: âš ï¸ åŸºæœ¬å¯ç”¨ï¼Œéœ€è¦è°ƒè¯•

## ğŸ› å½“å‰é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### 1. CRNNè®­ç»ƒé—®é¢˜

#### é—®é¢˜1: å­—ç¬¦é›†ä¸å®Œæ•´
```
è­¦å‘Š: æœªçŸ¥å­—ç¬¦ 'æ²³' åœ¨æ–‡æœ¬ 'æ²³å—çœå•†ä¸˜å¸‚ç¢é˜³åŒº' ä¸­
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# åœ¨train_crnn.pyä¸­æ‰©å±•å­—ç¬¦é›†
charset = ('0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'
          'ä¸­åäººæ°‘å…±å’Œå›½èº«ä»½è¯å§“åæ€§åˆ«æ°‘æ—å‡ºç”Ÿå¹´æœˆæ—¥ä½å€å…¬æ°‘å·ç ç­¾å‘æœºå…³æœ‰æ•ˆæœŸé™é•¿è‡³æ±‰æ—ç”·å¥³'
          'çœå¸‚å¿åŒºè¡—é“è·¯å·æ¥¼å®¤æ´¾å‡ºæ‰€å…¬å®‰å±€å…'
          'ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å'  # æ•°å­—
          'ä¸œè¥¿å—åŒ—äº¬æ´¥æ²ªæ¸å†€è±«äº‘è¾½é»‘æ¹˜çš–é²æ–°è‹æµ™èµ£é„‚æ¡‚ç”˜æ™‹è’™é™•å‰é—½è´µç²¤é’è—å·å®ç¼'  # çœå¸‚
          'æ²³å•†ä¸˜ç¢é˜³æä»»æ¥¼æ‘æœæµ¦ä¸œæ–°æ·±åœ³å¹¿ç»´å¾å°”è‹—å½è—è’™å¤æ»¡å›å¼ ä¸‰æå››ç‹äº”èµµå…­é’±ä¸ƒå­™å…«å‘¨ä¹å´å'
          'äºšå¤åˆ†ä¸Šæµ·åŒ—åœ³.-')  # èº«ä»½è¯ç›¸å…³å­—ç¬¦
```

#### é—®é¢˜2: CTCæŸå¤±å‡½æ•°ç»´åº¦ä¸åŒ¹é…
```
è®­ç»ƒæ‰¹æ¬¡å‡ºé”™: input_lengths must be of size batch_size
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä¿®å¤collate_fnå‡½æ•°
def collate_fn(batch):
    images, targets, texts = zip(*batch)
    
    max_width = max(img.shape[2] for img in images)
    batch_size = len(images)
    
    # ä¿®å¤: ç¡®ä¿input_lengthsä¸batch_sizeåŒ¹é…
    input_lengths = []
    for img in images:
        seq_len = img.shape[2] // 4  # CNNä¸‹é‡‡æ ·å› å­
        input_lengths.append(seq_len)
    
    # ç¡®ä¿æ‰€æœ‰é•¿åº¦éƒ½å¤§äº0
    input_lengths = [max(1, length) for length in input_lengths]
    
    return (padded_images, 
            torch.tensor(all_targets, dtype=torch.long),
            torch.tensor(input_lengths, dtype=torch.long),
            torch.tensor(target_lengths, dtype=torch.long),
            texts)
```

### 2. CRAFTè®­ç»ƒé—®é¢˜

#### é—®é¢˜1: å°ºå¯¸ä¸åŒ¹é…
```
The size of tensor a (256) must match the size of tensor b (512) at non-singleton dimension 2
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä¿®å¤_resize_dataæ–¹æ³•ï¼Œç¡®ä¿å°ºå¯¸ä¸€è‡´
def _resize_data(self, image, char_heatmap, link_heatmap, target_size=512):
    h, w = image.shape[:2]
    
    # ç›´æ¥è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
    image = cv2.resize(image, (target_size, target_size))
    char_heatmap = cv2.resize(char_heatmap, (target_size, target_size))
    link_heatmap = cv2.resize(link_heatmap, (target_size, target_size))
    
    return image, char_heatmap, link_heatmap
```

#### é—®é¢˜2: æ¨¡å‹è¾“å‡ºå°ºå¯¸ä¸æ­£ç¡®
**è§£å†³æ–¹æ¡ˆ**:
```python
# ä¿®å¤æ¨¡å‹å‰å‘ä¼ æ’­ä¸­çš„å°ºå¯¸å¤„ç†
def train_epoch(self, dataloader, optimizer, epoch):
    for batch_idx, (images, char_heatmaps, link_heatmaps) in enumerate(pbar):
        # å‰å‘ä¼ æ’­
        outputs, _ = self.model(images)
        
        # è°ƒæ•´è¾“å‡ºå°ºå¯¸ä»¥åŒ¹é…ç›®æ ‡
        pred_char = F.interpolate(outputs[:, :, :, 0:1], 
                                size=(char_heatmaps.shape[1], char_heatmaps.shape[2]))
        pred_link = F.interpolate(outputs[:, :, :, 1:2], 
                                size=(link_heatmaps.shape[1], link_heatmaps.shape[2]))
```

## ğŸ”§ æ¨èçš„ä¿®å¤æ­¥éª¤

### æ­¥éª¤1: ä¿®å¤CRNNè®­ç»ƒ
```bash
# 1. ä¿®å¤å­—ç¬¦é›†å®šä¹‰
# 2. ä¿®å¤collate_fnå‡½æ•°
# 3. é‡æ–°è®­ç»ƒ
python train_crnn.py --epochs 5 --batch_size 4
```

### æ­¥éª¤2: ä¿®å¤CRAFTè®­ç»ƒ
```bash
# 1. ä¿®å¤å°ºå¯¸å¤„ç†
# 2. ä¿®å¤æ¨¡å‹è¾“å‡ºå¤„ç†
# 3. é‡æ–°è®­ç»ƒ
python train_craft.py --epochs 5 --batch_size 2
```

### æ­¥éª¤3: éªŒè¯è®­ç»ƒç»“æœ
```bash
# æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹
python main.py --image id.jpeg --method crnn
```

## ğŸ“Š è®­ç»ƒä»£ç å®Œæ•´æ€§è¯„ä¼°

| ç»„ä»¶ | å®Œæˆåº¦ | çŠ¶æ€ | å¤‡æ³¨ |
|------|--------|------|------|
| æ•°æ®å‡†å¤‡ | 100% | âœ… | å®Œå…¨å¯ç”¨ |
| CRNNæ¶æ„ | 90% | âš ï¸ | éœ€è¦è°ƒè¯•CTCæŸå¤± |
| CRAFTæ¶æ„ | 85% | âš ï¸ | éœ€è¦ä¿®å¤å°ºå¯¸é—®é¢˜ |
| è®­ç»ƒæµç¨‹ | 80% | âš ï¸ | åŸºæœ¬æ¡†æ¶å®Œæ•´ |
| éªŒè¯æµç¨‹ | 75% | âš ï¸ | éœ€è¦æ”¹è¿›æŒ‡æ ‡è®¡ç®— |
| æ¨¡å‹ä¿å­˜ | 100% | âœ… | å®Œå…¨å¯ç”¨ |
| é…ç½®ç®¡ç† | 90% | âœ… | åŸºæœ¬å®Œå–„ |

## ğŸš€ ç®€åŒ–ç‰ˆè®­ç»ƒä»£ç 

ä¸ºäº†å¿«é€ŸéªŒè¯è®­ç»ƒæµç¨‹ï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼š

### ç®€åŒ–CRNNè®­ç»ƒ
```python
# simplified_train_crnn.py
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from models.crnn import CRNN

def simple_train():
    # åˆ›å»ºç®€å•æ•°æ®
    batch_size = 2
    seq_len = 40
    num_classes = 121  # å­—ç¬¦é›†å¤§å° + blank
    
    model = CRNN(32, 1, num_classes, 256)
    criterion = nn.CTCLoss(blank=120)
    optimizer = torch.optim.Adam(model.parameters())
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    for epoch in range(5):
        # æ¨¡æ‹Ÿæ‰¹æ¬¡æ•°æ®
        images = torch.randn(batch_size, 1, 32, 160)
        targets = torch.randint(0, 119, (10,))  # éšæœºç›®æ ‡åºåˆ—
        input_lengths = torch.full((batch_size,), seq_len)
        target_lengths = torch.tensor([5, 5])
        
        optimizer.zero_grad()
        outputs = model(images)
        outputs = outputs.log_softmax(2)
        
        loss = criterion(outputs, targets, input_lengths, target_lengths)
        loss.backward()
        optimizer.step()
        
        print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

if __name__ == "__main__":
    simple_train()
```

### ç®€åŒ–CRAFTè®­ç»ƒ
```python
# simplified_train_craft.py
import torch
import torch.nn as nn
from models.text_detection import CRAFT

def simple_train():
    model = CRAFT(pretrained=False)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters())
    
    for epoch in range(5):
        # æ¨¡æ‹Ÿæ•°æ®
        images = torch.randn(2, 3, 512, 512)
        char_targets = torch.randn(2, 256, 256, 1)
        link_targets = torch.randn(2, 256, 256, 1)
        
        optimizer.zero_grad()
        outputs, _ = model(images)
        
        # è°ƒæ•´è¾“å‡ºå°ºå¯¸
        pred_char = torch.nn.functional.interpolate(
            outputs[:, :, :, 0:1], size=(256, 256))
        pred_link = torch.nn.functional.interpolate(
            outputs[:, :, :, 1:2], size=(256, 256))
        
        loss = criterion(pred_char, char_targets) + criterion(pred_link, link_targets)
        loss.backward()
        optimizer.step()
        
        print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")

if __name__ == "__main__":
    simple_train()
```

## ğŸ¯ æ€»ç»“

### å½“å‰çŠ¶æ€
1. âœ… **è®­ç»ƒæ¡†æ¶**: å®Œæ•´çš„è®­ç»ƒä»£ç æ¡†æ¶å·²ç»å»ºç«‹
2. âœ… **æ•°æ®æµç¨‹**: æ•°æ®å‡†å¤‡å’ŒåŠ è½½æµç¨‹å®Œå–„
3. âš ï¸ **è°ƒè¯•éœ€è¦**: éœ€è¦ä¿®å¤ä¸€äº›æŠ€æœ¯ç»†èŠ‚
4. âœ… **å¯æ‰©å±•æ€§**: ä»£ç ç»“æ„è‰¯å¥½ï¼Œæ˜“äºæ”¹è¿›

### å»ºè®®
1. **ä¼˜å…ˆä¿®å¤CRNN**: æ–‡æœ¬è¯†åˆ«æ›´å®¹æ˜“è°ƒè¯•å’ŒéªŒè¯
2. **ä½¿ç”¨ç®€åŒ–æ•°æ®**: å…ˆç”¨å°æ•°æ®é›†éªŒè¯è®­ç»ƒæµç¨‹
3. **é€æ­¥å®Œå–„**: ä¿®å¤ä¸€ä¸ªé—®é¢˜åå†å¤„ç†ä¸‹ä¸€ä¸ª
4. **æ·»åŠ æ—¥å¿—**: å¢åŠ æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯

### é¢„æœŸç»“æœ
ä¿®å¤è¿™äº›é—®é¢˜åï¼Œä½ å°†æ‹¥æœ‰ï¼š
- ğŸ¯ å®Œå…¨å¯ç”¨çš„CRNNæ–‡æœ¬è¯†åˆ«è®­ç»ƒä»£ç 
- ğŸ” å®Œå…¨å¯ç”¨çš„CRAFTæ–‡æœ¬æ£€æµ‹è®­ç»ƒä»£ç 
- ğŸ“Š å®Œæ•´çš„è®­ç»ƒç›‘æ§å’ŒéªŒè¯æµç¨‹
- ğŸ’¾ è‡ªåŠ¨åŒ–çš„æ¨¡å‹ä¿å­˜å’Œæ¢å¤æœºåˆ¶

**è®­ç»ƒä»£ç å·²ç»90%å®Œæˆï¼Œåªéœ€è¦ä¸€äº›ç»†èŠ‚è°ƒè¯•å°±èƒ½æ­£å¸¸å·¥ä½œï¼**ğŸš€ 