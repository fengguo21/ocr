"""
èº«ä»½è¯è¯†åˆ«ç³»ç»Ÿä¸»ç¨‹åº
æ”¯æŒå¤šç§OCRæ–¹æ¡ˆï¼š
1. è‡ªå®šä¹‰CRNNæ¨¡å‹
2. PaddleOCR
3. EasyOCR
4. æ··åˆæ–¹æ¡ˆ
"""

import os
import sys
import cv2
import numpy as np
import argparse
from typing import Dict, List, Tuple, Optional
import json
import time

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å°è¯•å¯¼å…¥æ·±åº¦å­¦ä¹ ä¾èµ–
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸  PyTorchæœªå®‰è£…ï¼ŒCRNNæ¨¡å‹åŠŸèƒ½å°†ä¸å¯ç”¨")

from utils.image_processing import IDCardPreprocessor
from utils.id_info_extractor import IDCardInfoExtractor

# åªæœ‰åœ¨PyTorchå¯ç”¨æ—¶æ‰å¯¼å…¥æ¨¡å‹
if TORCH_AVAILABLE:
    from models.crnn import CRNN, AttentionCRNN
    from models.text_detection import TextDetector


class IDCardRecognizer:
    """èº«ä»½è¯è¯†åˆ«å™¨ä¸»ç±»"""
    
    def __init__(self, config: Dict):
        self.config = config
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.preprocessor = IDCardPreprocessor()
        self.info_extractor = IDCardInfoExtractor()
        
        # åˆå§‹åŒ–OCRæ¨¡å‹
        self.ocr_method = config.get('ocr_method', 'paddleocr')
        
        # æ£€æŸ¥æ·±åº¦å­¦ä¹ æ”¯æŒ
        if TORCH_AVAILABLE:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = 'cpu'
        
        self._init_ocr_models()
        
        print(f"åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"OCRæ–¹æ³•: {self.ocr_method}")

    def _init_ocr_models(self):
        """åˆå§‹åŒ–OCRæ¨¡å‹"""
        if self.ocr_method == 'paddleocr':
            self._init_paddleocr()
        elif self.ocr_method == 'easyocr':
            self._init_easyocr()
        elif self.ocr_method == 'crnn':
            if TORCH_AVAILABLE:
                self._init_crnn()
            else:
                print("âŒ CRNNæ¨¡å‹éœ€è¦PyTorchæ”¯æŒï¼Œè¯·å®‰è£…PyTorchæˆ–ä½¿ç”¨å…¶ä»–OCRæ–¹æ³•")
                sys.exit(1)
        elif self.ocr_method == 'hybrid':
            self._init_hybrid()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„OCRæ–¹æ³•: {self.ocr_method}")

    def _init_paddleocr(self):
        """åˆå§‹åŒ–PaddleOCR"""
        try:
            from paddleocr import PaddleOCR
            # ä½¿ç”¨æœ€ç®€å•çš„å‚æ•°é…ç½®
            self.ocr_engine = PaddleOCR(lang='ch')
            print("PaddleOCRåˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            print("PaddleOCRæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install paddleocr")
            sys.exit(1)
        except Exception as e:
            print(f"PaddleOCRåˆå§‹åŒ–å¤±è´¥: {e}")
            sys.exit(1)

    def _init_easyocr(self):
        """åˆå§‹åŒ–EasyOCR"""
        try:
            import easyocr
            gpu_available = TORCH_AVAILABLE and torch.cuda.is_available()
            self.ocr_engine = easyocr.Reader(['ch_sim', 'en'], gpu=gpu_available)
            print("EasyOCRåˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            print("EasyOCRæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install easyocr")
            sys.exit(1)

    def _init_crnn(self):
        """åˆå§‹åŒ–è‡ªå®šä¹‰CRNNæ¨¡å‹"""
        if not TORCH_AVAILABLE:
            raise ImportError("CRNNæ¨¡å‹éœ€è¦PyTorchæ”¯æŒ")
            
        # å­—ç¬¦é›†å®šä¹‰
        self.charset = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' + \
                      'ä¸­åäººæ°‘å…±å’Œå›½èº«ä»½è¯å§“åæ€§åˆ«æ°‘æ—å‡ºç”Ÿå¹´æœˆæ—¥ä½å€å…¬æ°‘å·ç ç­¾å‘æœºå…³æœ‰æ•ˆæœŸé™é•¿è‡³æ±‰æ—ç”·å¥³' + \
                      'çœå¸‚å¿åŒºè¡—é“è·¯å·æ¥¼å®¤æ´¾å‡ºæ‰€å…¬å®‰å±€å…'
        
        self.char_to_idx = {char: idx for idx, char in enumerate(self.charset)}
        self.idx_to_char = {idx: char for idx, char in enumerate(self.charset)}
        
        # åˆå§‹åŒ–æ¨¡å‹
        model_config = self.config.get('crnn_config', {})
        self.crnn_model = CRNN(
            img_h=model_config.get('img_h', 32),
            nc=model_config.get('nc', 1),
            nclass=len(self.charset) + 1,  # +1 for blank
            nh=model_config.get('nh', 256)
        ).to(self.device)
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        model_path = model_config.get('model_path')
        if model_path and os.path.exists(model_path):
            self.crnn_model.load_state_dict(torch.load(model_path, map_location=self.device))
            print(f"åŠ è½½CRNNæ¨¡å‹: {model_path}")
        else:
            print("æœªæ‰¾åˆ°é¢„è®­ç»ƒCRNNæ¨¡å‹ï¼Œå°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
        
        self.crnn_model.eval()
        
        # åˆå§‹åŒ–æ–‡æœ¬æ£€æµ‹å™¨
        self.text_detector = TextDetector(device=self.device)

    def _init_hybrid(self):
        """åˆå§‹åŒ–æ··åˆæ–¹æ¡ˆ"""
        self._init_paddleocr()
        self._init_easyocr()
        print("æ··åˆOCRæ–¹æ¡ˆåˆå§‹åŒ–æˆåŠŸ")

    def recognize_image(self, image_path: str) -> Dict[str, str]:
        """
        è¯†åˆ«èº«ä»½è¯å›¾åƒ
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            
        Returns:
            è¯†åˆ«ç»“æœå­—å…¸
        """
        start_time = time.time()
        
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        
        print(f"å¼€å§‹å¤„ç†å›¾åƒ: {image_path}")
        
        # å›¾åƒé¢„å¤„ç†
        processed_image = self.preprocessor.preprocess_for_ocr(image, training=False)
        print(f"é¢„å¤„ç†å®Œæˆï¼Œå›¾åƒå°ºå¯¸: {processed_image.shape}")
        
        # OCRè¯†åˆ«
        ocr_results = self._perform_ocr(processed_image)
        print(f"OCRè¯†åˆ«åˆ°{len(ocr_results)}ä¸ªæ–‡æœ¬åŒºåŸŸ")
        
        # æ˜¾ç¤ºè¯†åˆ«çš„æ–‡æœ¬å†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        if ocr_results:
            print("è¯†åˆ«çš„æ–‡æœ¬å†…å®¹:")
            for i, (text, confidence) in enumerate(ocr_results):
                print(f"  {i+1}. '{text}' (ç½®ä¿¡åº¦: {confidence:.3f})")
        else:
            print("âš ï¸  æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬")
        
        # ä¿¡æ¯æå–
        # é¦–å…ˆåˆ¤æ–­èº«ä»½è¯æ­£é¢è¿˜æ˜¯èƒŒé¢
        full_text = ' '.join([text for text, _ in ocr_results])
        is_front = self.info_extractor._is_front_side(full_text, ocr_results)
        print(f"èº«ä»½è¯é¢åˆ«åˆ¤æ–­: {'æ­£é¢' if is_front else 'èƒŒé¢'}")
        
        id_info = self.info_extractor.extract_info(ocr_results)
        
        # è®¡ç®—è€—æ—¶
        processing_time = time.time() - start_time
        id_info['å¤„ç†æ—¶é—´'] = f"{processing_time:.2f}ç§’"
        
        print(f"è¯†åˆ«å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
        
        return id_info

    def _perform_ocr(self, image: np.ndarray) -> List[Tuple[str, float]]:
        """æ‰§è¡ŒOCRè¯†åˆ«"""
        if self.ocr_method == 'paddleocr':
            return self._paddleocr_recognize(image)
        elif self.ocr_method == 'easyocr':
            return self._easyocr_recognize(image)
        elif self.ocr_method == 'crnn':
            return self._crnn_recognize(image)
        elif self.ocr_method == 'hybrid':
            return self._hybrid_recognize(image)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„OCRæ–¹æ³•: {self.ocr_method}")

    def _paddleocr_recognize(self, image: np.ndarray) -> List[Tuple[str, float]]:
        """PaddleOCRè¯†åˆ«"""
        try:
            # ä½¿ç”¨æ–°ç‰ˆPaddleOCRçš„predictæ–¹æ³•
            if hasattr(self.ocr_engine, 'predict'):
                results = self.ocr_engine.predict(image)
                print(f"PaddleOCR predictç»“æœç±»å‹: {type(results)}")
                print(f"PaddleOCR predictç»“æœ: {results}")
            else:
                # å°è¯•æ—§ç‰ˆæœ¬çš„ocræ–¹æ³•
                results = self.ocr_engine.ocr(image)
                
        except Exception as e:
            print(f"PaddleOCRè°ƒç”¨å¤±è´¥: {e}")
            return []
        
        ocr_results = []
        
        # å¤„ç†æ–°ç‰ˆæœ¬PaddleOCRçš„ç»“æœæ ¼å¼
        try:
            if results and isinstance(results, list) and len(results) > 0:
                # è·å–ç¬¬ä¸€ä¸ªç»“æœé¡¹
                result_item = results[0]
                
                if isinstance(result_item, dict):
                    # æ–°ç‰ˆPaddleOCRæ ¼å¼ï¼šåŒ…å«rec_textså’Œrec_scores
                    if 'rec_texts' in result_item and 'rec_scores' in result_item:
                        texts = result_item.get('rec_texts', [])
                        scores = result_item.get('rec_scores', [])
                        
                        print(f"è¯†åˆ«åˆ°çš„æ–‡æœ¬: {texts}")
                        print(f"å¯¹åº”çš„ç½®ä¿¡åº¦: {scores}")
                        
                        for text, score in zip(texts, scores):
                            if text and text.strip():  # è¿‡æ»¤ç©ºæ–‡æœ¬
                                ocr_results.append((text.strip(), float(score)))
                    
                    # å…¶ä»–å¯èƒ½çš„æ ¼å¼
                    elif 'rec_text' in result_item:
                        text = result_item.get('rec_text', '')
                        score = result_item.get('rec_score', 0.0)
                        if text.strip():
                            ocr_results.append((text, float(score)))
                    elif 'text' in result_item:
                        text = result_item.get('text', '')
                        score = result_item.get('score', 0.0)
                        if text.strip():
                            ocr_results.append((text, float(score)))
                
        except Exception as e:
            print(f"è§£æPaddleOCRç»“æœå¤±è´¥: {e}")
            print(f"åŸå§‹ç»“æœç±»å‹: {type(results)}")
            if results:
                print(f"ç¬¬ä¸€ä¸ªç»“æœé¡¹ç±»å‹: {type(results[0])}")
                if isinstance(results[0], dict):
                    print(f"å­—å…¸é”®: {list(results[0].keys())}")
        
        return ocr_results

    def _easyocr_recognize(self, image: np.ndarray) -> List[Tuple[str, float]]:
        """EasyOCRè¯†åˆ«"""
        results = self.ocr_engine.readtext(image)
        ocr_results = []
        
        for item in results:
            text = item[1]
            confidence = item[2]
            ocr_results.append((text, confidence))
        
        return ocr_results

    def _crnn_recognize(self, image: np.ndarray) -> List[Tuple[str, float]]:
        """CRNNè¯†åˆ«"""
        if not TORCH_AVAILABLE:
            raise ImportError("CRNNè¯†åˆ«éœ€è¦PyTorchæ”¯æŒ")
        
        # ç¡®ä¿å›¾åƒæ˜¯3é€šé“çš„ï¼ˆTextDetectoréœ€è¦RGBè¾“å…¥ï¼‰
        if len(image.shape) == 2:
            # å¦‚æœæ˜¯ç°åº¦å›¾ï¼Œè½¬æ¢ä¸º3é€šé“
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        elif image.shape[2] == 1:
            # å¦‚æœæ˜¯å•é€šé“ï¼Œå¤åˆ¶åˆ°3é€šé“
            image = np.repeat(image, 3, axis=2)
            
        try:
            # æ–‡æœ¬æ£€æµ‹
            boxes, _ = self.text_detector.detect_text(image)
            print(f"æ–‡æœ¬æ£€æµ‹ç»“æœ: {boxes}")
            
            ocr_results = []
            for box in boxes:
                # æå–æ–‡æœ¬åŒºåŸŸ
                x1, y1 = int(box[0][0]), int(box[0][1])
                x2, y2 = int(box[2][0]), int(box[2][1])
                
                # è¾¹ç•Œæ£€æŸ¥
                h, w = image.shape[:2]
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(w, x2), min(h, y2)
                
                if x2 > x1 and y2 > y1:  # ç¡®ä¿åŒºåŸŸæœ‰æ•ˆ
                    text_region = image[y1:y2, x1:x2]
                    
                    # æ–‡æœ¬è¯†åˆ«
                    text, confidence = self._recognize_text_region(text_region)
                    if text.strip():
                        ocr_results.append((text, confidence))
            
            return ocr_results
            
        except Exception as e:
            print(f"CRNNæ–‡æœ¬æ£€æµ‹å¤±è´¥: {e}")
            # å¦‚æœæ–‡æœ¬æ£€æµ‹å¤±è´¥ï¼Œç›´æ¥å¯¹æ•´ä¸ªå›¾åƒè¿›è¡Œè¯†åˆ«
            return self._fallback_crnn_recognition(image)

    def _recognize_text_region(self, region: np.ndarray) -> Tuple[str, float]:
        """è¯†åˆ«å•ä¸ªæ–‡æœ¬åŒºåŸŸ"""
        # é¢„å¤„ç†æ–‡æœ¬åŒºåŸŸ
        region = self.preprocessor.preprocess_text_region(region)
        
        # è°ƒæ•´å°ºå¯¸
        h, w = region.shape
        target_h = 32
        target_w = int(w * target_h / h)
        region = cv2.resize(region, (target_w, target_h))
        
        # è½¬æ¢ä¸ºtensor
        region = region.astype(np.float32) / 255.0
        region = torch.from_numpy(region).unsqueeze(0).unsqueeze(0).to(self.device)
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            output = self.crnn_model(region)
            output = torch.nn.functional.log_softmax(output, dim=2)
        
        # è§£ç ç»“æœ
        text, confidence = self._decode_crnn_output(output)
        
        return text, confidence

    def _decode_crnn_output(self, output: 'torch.Tensor') -> Tuple[str, float]:
        """è§£ç CRNNè¾“å‡º"""
        # ç®€å•çš„è´ªå¿ƒè§£ç 
        output = output.squeeze(0).cpu().numpy()
        
        # è·å–æœ€å¯èƒ½çš„å­—ç¬¦åºåˆ—
        predicted_chars = []
        confidences = []
        
        for t in range(output.shape[0]):
            char_probs = output[t]
            char_idx = np.argmax(char_probs)
            
            if char_idx != len(self.charset):  # ä¸æ˜¯blank
                if char_idx in self.idx_to_char:
                    predicted_chars.append(self.idx_to_char[char_idx])
                    confidences.append(np.exp(char_probs[char_idx]))
        
        # å»é™¤é‡å¤å­—ç¬¦
        if predicted_chars:
            final_text = predicted_chars[0]
            final_confidences = [confidences[0]]
            
            for i in range(1, len(predicted_chars)):
                if predicted_chars[i] != predicted_chars[i-1]:
                    final_text += predicted_chars[i]
                    final_confidences.append(confidences[i])
            
            avg_confidence = np.mean(final_confidences) if final_confidences else 0.0
            return final_text, avg_confidence
        
        return "", 0.0

    def _fallback_crnn_recognition(self, image: np.ndarray) -> List[Tuple[str, float]]:
        """
        å½“æ–‡æœ¬æ£€æµ‹å¤±è´¥æ—¶çš„fallbackè¯†åˆ«æ–¹æ³•
        ç›´æ¥å°†æ•´ä¸ªå›¾åƒåˆ†å‰²æˆå¯èƒ½çš„æ–‡æœ¬åŒºåŸŸè¿›è¡Œè¯†åˆ«
        """
        try:
            # ä½¿ç”¨ä¼ ç»Ÿçš„æ–‡æœ¬åŒºåŸŸæå–æ–¹æ³•
            text_regions = self.preprocessor.extract_text_regions(image)
            
            ocr_results = []
            for region in text_regions:
                text, confidence = self._recognize_text_region(region)
                if text.strip():
                    ocr_results.append((text, confidence))
            
            # å¦‚æœä¼ ç»Ÿæ–¹æ³•ä¹Ÿæ²¡æœ‰ç»“æœï¼Œç›´æ¥å¯¹æ•´ä¸ªå›¾åƒè¿›è¡Œè¯†åˆ«
            if not ocr_results:
                print("ä½¿ç”¨æ•´ä¸ªå›¾åƒè¿›è¡ŒCRNNè¯†åˆ«...")
                text, confidence = self._recognize_text_region(image)
                if text.strip():
                    ocr_results.append((text, confidence))
            
            return ocr_results
            
        except Exception as e:
            print(f"Fallbackè¯†åˆ«ä¹Ÿå¤±è´¥: {e}")
            return []

    def _hybrid_recognize(self, image: np.ndarray) -> List[Tuple[str, float]]:
        """æ··åˆè¯†åˆ«æ–¹æ¡ˆ"""
        # ä½¿ç”¨å¤šä¸ªOCRå¼•æ“è¯†åˆ«
        paddle_results = []
        easy_results = []
        
        # å®‰å…¨è°ƒç”¨å„ä¸ªOCRå¼•æ“
        try:
            paddle_results = self._paddleocr_recognize(image)
        except Exception as e:
            print(f"PaddleOCRè¯†åˆ«å¤±è´¥: {e}")
        
        try:
            easy_results = self._easyocr_recognize(image)
        except Exception as e:
            print(f"EasyOCRè¯†åˆ«å¤±è´¥: {e}")
        
        # åˆå¹¶ç»“æœï¼ˆç®€å•ç­–ç•¥ï¼šé€‰æ‹©ç½®ä¿¡åº¦è¾ƒé«˜çš„ç»“æœï¼‰
        combined_results = []
        
        # å°†æ‰€æœ‰ç»“æœæ”¾å…¥å­—å…¸ï¼ŒæŒ‰æ–‡æœ¬å†…å®¹åˆ†ç»„
        text_dict = {}
        
        for text, conf in paddle_results:
            if text not in text_dict or conf > text_dict[text]:
                text_dict[text] = conf
        
        for text, conf in easy_results:
            if text not in text_dict or conf > text_dict[text]:
                text_dict[text] = conf
        
        # è½¬æ¢å›åˆ—è¡¨æ ¼å¼
        combined_results = [(text, conf) for text, conf in text_dict.items()]
        
        return combined_results

    def batch_recognize(self, image_dir: str, output_file: str = None):
        """æ‰¹é‡è¯†åˆ«"""
        results = []
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        
        for filename in os.listdir(image_dir):
            if any(filename.lower().endswith(ext) for ext in image_extensions):
                image_path = os.path.join(image_dir, filename)
                try:
                    result = self.recognize_image(image_path)
                    result['æ–‡ä»¶å'] = filename
                    results.append(result)
                    print(f"å®Œæˆ: {filename}")
                except Exception as e:
                    print(f"å¤„ç† {filename} æ—¶å‡ºé”™: {str(e)}")
        
        # ä¿å­˜ç»“æœ
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        return results


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–ç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥ç³»ç»Ÿä¾èµ–...")
    
    dependencies = {
        'OpenCV': cv2.__version__,
        'NumPy': np.__version__,
    }
    
    if TORCH_AVAILABLE:
        dependencies['PyTorch'] = torch.__version__
        dependencies['CUDAæ”¯æŒ'] = 'æ˜¯' if torch.cuda.is_available() else 'å¦'
    else:
        dependencies['PyTorch'] = 'æœªå®‰è£…'
    
    # æ£€æŸ¥OCRå¼•æ“
    try:
        import paddleocr
        dependencies['PaddleOCR'] = 'å·²å®‰è£…'
    except ImportError:
        dependencies['PaddleOCR'] = 'æœªå®‰è£…'
    
    try:
        import easyocr
        dependencies['EasyOCR'] = 'å·²å®‰è£…'
    except ImportError:
        dependencies['EasyOCR'] = 'æœªå®‰è£…'
    
    print("\nğŸ“‹ ä¾èµ–æ£€æŸ¥ç»“æœ:")
    for name, version in dependencies.items():
        print(f"  {name}: {version}")
    
    # æ¨èOCRæ–¹æ³•
    if dependencies.get('PaddleOCR') == 'å·²å®‰è£…':
        print("\nâœ… æ¨èä½¿ç”¨ PaddleOCR (--method paddleocr)")
    elif dependencies.get('EasyOCR') == 'å·²å®‰è£…':
        print("\nâœ… æ¨èä½¿ç”¨ EasyOCR (--method easyocr)")
    else:
        print("\nâš ï¸  å»ºè®®å®‰è£… PaddleOCR æˆ– EasyOCR")
        print("   pip install paddleocr paddlepaddle")
        print("   pip install easyocr")


def main():
    parser = argparse.ArgumentParser(description='èº«ä»½è¯è¯†åˆ«ç³»ç»Ÿ')
    parser.add_argument('--image', type=str, help='è¾“å…¥å›¾åƒè·¯å¾„')
    parser.add_argument('--batch', type=str, help='æ‰¹é‡å¤„ç†ç›®å½•')
    parser.add_argument('--output', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--method', type=str, default='paddleocr', 
                       choices=['paddleocr', 'easyocr', 'crnn', 'hybrid'],
                       help='OCRæ–¹æ³•')
    parser.add_argument('--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--check-deps', action='store_true', help='æ£€æŸ¥ä¾èµ–ç¯å¢ƒ')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ä¾èµ–
    if args.check_deps:
        check_dependencies()
        return
    
    # å¦‚æœæ²¡æœ‰ä»»ä½•å‚æ•°ï¼Œæ˜¾ç¤ºä¾èµ–æ£€æŸ¥
    if not any([args.image, args.batch]):
        check_dependencies()
        print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
        print("  python main.py --image idcard.jpg --method paddleocr")
        print("  python main.py --batch images/ --output results.json")
        print("  python main.py --check-deps")
        return
    
    # åŠ è½½é…ç½®
    config = {'ocr_method': args.method}
    if args.config and os.path.exists(args.config):
        with open(args.config, 'r', encoding='utf-8') as f:
            config.update(json.load(f))
    
    # åˆå§‹åŒ–è¯†åˆ«å™¨
    try:
        recognizer = IDCardRecognizer(config)
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        print("è¯·æ£€æŸ¥ä¾èµ–å®‰è£…æˆ–ä½¿ç”¨ --check-deps æ£€æŸ¥ç¯å¢ƒ")
        return
    
    if args.image:
        # å•å¼ å›¾åƒè¯†åˆ«
        try:
            result = recognizer.recognize_image(args.image)
            print("\nè¯†åˆ«ç»“æœ:")
            print("=" * 50)
            for key, value in result.items():
                print(f"{key}: {value}")
            
            if args.output:
                with open(args.output, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"\nç»“æœå·²ä¿å­˜åˆ°: {args.output}")
        except Exception as e:
            print(f"âŒ è¯†åˆ«å¤±è´¥: {str(e)}")
    
    elif args.batch:
        # æ‰¹é‡è¯†åˆ«
        try:
            results = recognizer.batch_recognize(args.batch, args.output)
            print(f"\næ‰¹é‡å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(results)} å¼ å›¾åƒ")
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    # ç¡¬ç¼–ç å‚æ•° - ç›´æ¥è¿è¡Œæ—¶ä½¿ç”¨è¿™äº›å‚æ•°
    import sys
    sys.argv = ['main.py', '--image', 'id.jpeg', '--method', 'crnn']
    
    main()
